"""
Streamlit í†µê³„ í•™ìŠµ ì•± - "ì–´ë–¤ ëŒ€í‘¯ê°’ì´ ì¢‹ì„ê¹Œ?" í˜ì´ì§€
ì‹¤ì œ OpenAI API ì—°ë™ ë²„ì „

í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
pip install streamlit openai pandas numpy

Streamlit Secrets ì„¤ì •:
.streamlit/secrets.toml íŒŒì¼ì— ë‹¤ìŒ ì¶”ê°€:
OPENAI_API_KEY = "your-openai-api-key-here"

ë˜ëŠ” Streamlit Cloudì—ì„œ Advanced settings > Secretsì— ì¶”ê°€:
OPENAI_API_KEY = "your-openai-api-key-here"
"""

import streamlit as st
import pandas as pd
import numpy as np
import time
from collections import Counter
import openai
from openai import OpenAI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¤” ì–´ë–¤ ëŒ€í‘¯ê°’ì´ ì¢‹ì„ê¹Œ?",
    page_icon="ğŸ“Š",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
.main-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}

.scenario-box {
    background: #f8f9fa;
    border: 2px solid #667eea;
    border-radius: 10px;
    padding: 1.5rem;
    margin: 1rem 0;
}

.stats-display {
    background: #e6f3ff;
    border-radius: 8px;
    padding: 1rem;
    margin: 1rem 0;
}

.data-item {
    background: #667eea;
    color: white;
    padding: 8px 12px;
    margin: 4px;
    border-radius: 20px;
    display: inline-block;
    font-weight: bold;
}

.outlier {
    background: #fc8181 !important;
}

.mode-highlight {
    background: #ffd700 !important;
    color: #333 !important;
}

.feedback-positive {
    background: #d4edda;
    color: #155724;
    padding: 1rem;
    border-radius: 8px;
    border-left: 5px solid #28a745;
}

.feedback-negative {
    background: #f8d7da;
    color: #721c24;
    padding: 1rem;
    border-radius: 8px;
    border-left: 5px solid #dc3545;
}

.ai-section {
    background: #f0f8ff;
    border: 2px solid #4299e1;
    border-radius: 10px;
    padding: 1.5rem;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ¤” ì–´ë–¤ ëŒ€í‘¯ê°’ì´ ì¢‹ì„ê¹Œ?</h1>
    <p>ê°™ì€ ìë£Œë¼ë„ ìƒí™©ê³¼ ëª©ì ì— ë”°ë¼ <strong>ì ì ˆí•œ ëŒ€í‘¯ê°’ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”!</strong> ğŸ¯</p>
</div>
""", unsafe_allow_html=True)

# OpenAI API ì„¤ì • - ì¡°ìš©íˆ ì²˜ë¦¬
@st.cache_resource
def init_openai():
    # ë°©ë²• 1: Streamlit secretsì—ì„œ ê°€ì ¸ì˜¤ê¸° (ë°°í¬ìš©)
    try:
        return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    except:
        pass
    
    # ë°©ë²• 2: í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    import os
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return OpenAI(api_key=api_key)
    
    # API í‚¤ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)
    return None

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = init_openai()
USE_AI = client is not None

# ìƒíƒœ í‘œì‹œ (ë””ë²„ê¹…ìš© - ë‚˜ì¤‘ì— ì œê±° ê°€ëŠ¥)
if USE_AI:
    st.success("ğŸ¤– ì‹¤ì œ AI ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤!")
else:
    st.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤ (ë°°í¬ ì‹œ ì‹¤ì œ AIë¡œ ì „í™˜)")

# AI í”¼ë“œë°± í•¨ìˆ˜ (ì‹¤ì œ OpenAI API ì‚¬ìš©)
async def get_ai_feedback(scenario_id, selected_stat, reason):
    """ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•œ í”¼ë“œë°± ìƒì„±"""
    try:
        scenario_context = {
            1: "ì œê¸°ì°¨ê¸° íšŸìˆ˜ ë°ì´í„°: [4, 5, 6, 6, 6, 7, 7, 23]. ì—¬ê¸°ì„œ 23ì€ ê·¹ë‹¨ê°’ì…ë‹ˆë‹¤.",
            2: "ì‹ ë°œ íŒë§¤ ì‚¬ì´ì¦ˆ ë°ì´í„°: [250, 250, 250, 260, 260, 270, 280]. 250ì´ ê°€ì¥ ë§ì´ íŒ”ë ¸ìŠµë‹ˆë‹¤."
        }
        
        prompt = f"""
ë‹¹ì‹ ì€ ì¤‘í•™êµ í†µê³„ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ ëŒ€í‘¯ê°’ ë¬¸ì œì— ëŒ€í•´ ë‹µë³€í–ˆìŠµë‹ˆë‹¤.

ìƒí™©: {scenario_context[scenario_id]}
í•™ìƒì´ ì„ íƒí•œ ëŒ€í‘¯ê°’: {selected_stat}
í•™ìƒì˜ ì´ìœ : {reason}

í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³  í”¼ë“œë°±í•´ì£¼ì„¸ìš”:
1. ì„ íƒí•œ ëŒ€í‘¯ê°’ì´ ì ì ˆí•œì§€ íŒë‹¨
2. ì´ìœ ê°€ íƒ€ë‹¹í•œì§€ ë¶„ì„
3. ê°„ë‹¨í•˜ê³  ì¹œê·¼í•œ í”¼ë“œë°± ì œê³µ (2-3ë¬¸ì¥)
4. ì¹­ì°¬ ë˜ëŠ” ê°œì„ ì  ì œì‹œ

ì‘ë‹µ í˜•ì‹:
í‰ê°€: [ì •ë‹µ/ë¶€ë¶„ì •ë‹µ/ì˜¤ë‹µ]
í”¼ë“œë°±: [ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 2-3ë¬¸ì¥]
"""

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# AI ì˜ˆì‹œ ë¶„ì„ í•¨ìˆ˜ (ì‹¤ì œ OpenAI API ì‚¬ìš©)
async def analyze_stat_example(example_text, stat_type):
    """ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•œ ì˜ˆì‹œ ë¶„ì„"""
    try:
        stat_names = {'mean': 'í‰ê· ', 'median': 'ì¤‘ì•™ê°’', 'mode': 'ìµœë¹ˆê°’'}
        stat_name = stat_names[stat_type]
        
        prompt = f"""
ë‹¹ì‹ ì€ ì¤‘í•™êµ í†µê³„ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ {stat_name}ì„ ì‚¬ìš©í•˜ëŠ” ìƒí™© ì˜ˆì‹œë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.

í•™ìƒì˜ ì˜ˆì‹œ: {example_text}

ì´ ì˜ˆì‹œê°€ {stat_name}ì„ ì‚¬ìš©í•˜ê¸°ì— ì ì ˆí•œ ìƒí™©ì¸ì§€ í‰ê°€í•´ì£¼ì„¸ìš”:

{stat_name}ì´ ì ì ˆí•œ ê²½ìš°:
- í‰ê· : ìë£Œê°€ ê³ ë¥´ê²Œ ë¶„í¬, ê·¹ë‹¨ê°’ ì—†ìŒ, ì „ì²´ì  ìˆ˜ì¤€ íŒŒì•…
- ì¤‘ì•™ê°’: ê·¹ë‹¨ê°’ ì¡´ì¬, ì¹˜ìš°ì¹œ ë¶„í¬, ì¤‘ê°„ê°’ì´ ì¤‘ìš”
- ìµœë¹ˆê°’: ë¹ˆë„ê°€ ì¤‘ìš”, ê°€ì¥ í”í•œ ê°’, ë²”ì£¼í˜• ìë£Œ

ì‘ë‹µ í˜•ì‹:
í‰ê°€: [ì ì ˆí•¨/ë¶€ë¶„ì ì ˆí•¨/ë¶€ì ì ˆí•¨]
í”¼ë“œë°±: [ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 1-2ë¬¸ì¥]
"""

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=150,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'answers_submitted' not in st.session_state:
    st.session_state.answers_submitted = {}
if 'ai_examples_checked' not in st.session_state:
    st.session_state.ai_examples_checked = {}
if 'answers_submitted' not in st.session_state:
    st.session_state.answers_submitted = {}
if 'ai_examples_checked' not in st.session_state:
    st.session_state.ai_examples_checked = {}

# í†µê³„ ê³„ì‚° í•¨ìˆ˜
def calculate_stats(data):
    mean = np.mean(data)
    median = np.median(data)
    mode_counter = Counter(data)
    mode = mode_counter.most_common(1)[0][0]
    return {
        'mean': round(mean, 1),
        'median': median,
        'mode': mode
    }

# ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
scenarios = {
    1: {
        'title': 'ì˜ˆì œ 1: ì œê¸°ì°¨ê¸° íšŸìˆ˜',
        'data': [4, 5, 6, 6, 6, 7, 7, 23],
        'question': '23ì²˜ëŸ¼ ê·¹ë‹¨ì ìœ¼ë¡œ í° ê°’ì´ ë¼ì–´ ìˆë‹¤ë©´ í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ì¤‘ ì–´ë–¤ ê°’ì´ ë” ì ì ˆí• ê¹Œìš”?',
        'outlier_index': 7
    },
    2: {
        'title': 'ì˜ˆì œ 2: ì‹ ë°œ íŒë§¤ ì‚¬ì´ì¦ˆ',
        'data': [250, 250, 250, 260, 260, 270, 280],
        'question': 'ê°€ì¥ ë§ì´ íŒ”ë¦° ì‚¬ì´ì¦ˆë¥¼ ì•Œê³  ì‹¶ë‹¤ë©´ í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ì¤‘ ì–´ë–¤ ê°’ì´ ê°€ì¥ ìœ ìš©í• ê¹Œìš”?',
        'mode_indices': [0, 1, 2]
    }
}

st.header("ğŸ“Š ì˜ˆì œ ë¶„ì„ â€” ì–´ë–¤ ëŒ€í‘¯ê°’ì´ ì ì ˆí• ê¹Œ?")

# ë‘ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
col1, col2 = st.columns(2)

for i, (scenario_id, scenario) in enumerate(scenarios.items()):
    with col1 if i == 0 else col2:
        st.markdown(f"""
        <div class="scenario-box">
            <h3>{scenario['title']}</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # ë°ì´í„° í‘œì‹œ
        data_html = ""
        for idx, value in enumerate(scenario['data']):
            if scenario_id == 1 and idx == scenario.get('outlier_index'):
                data_html += f'<span class="data-item outlier">{value}</span> '
            elif scenario_id == 2 and idx in scenario.get('mode_indices', []):
                data_html += f'<span class="data-item mode-highlight">{value}</span> '
            else:
                data_html += f'<span class="data-item">{value}</span> '
        
        st.markdown(f"**ë°ì´í„°:** {data_html}", unsafe_allow_html=True)
        
        # ëŒ€í‘¯ê°’ ê³„ì‚° ë° í‘œì‹œ
        stats = calculate_stats(scenario['data'])
        
        with st.expander("ğŸ“ˆ ëŒ€í‘¯ê°’ ë³´ê¸°", expanded=True):
            st.markdown(f"""
            <div class="stats-display">
                <strong>ğŸ“ í‰ê· :</strong> {stats['mean']}<br>
                <strong>ğŸ“ ì¤‘ì•™ê°’:</strong> {stats['median']}<br>
                <strong>ğŸ¯ ìµœë¹ˆê°’:</strong> {stats['mode']}
            </div>
            """, unsafe_allow_html=True)
            
            st.info(f"â“ {scenario['question']}")
        
        # ë‹µë³€ ì…ë ¥
        st.subheader("ğŸ’­ ë‹¹ì‹ ì˜ ë‹µë³€")
        
        best_stat = st.selectbox(
            "ê°€ì¥ ì ì ˆí•œ ëŒ€í‘¯ê°’:",
            ["ì„ íƒí•˜ì„¸ìš”", "í‰ê· ", "ì¤‘ì•™ê°’", "ìµœë¹ˆê°’"],
            key=f"stat_select_{scenario_id}"
        )
        
        reason = st.text_area(
            "ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
            placeholder="ì™œ ì´ ëŒ€í‘¯ê°’ì´ ê°€ì¥ ì ì ˆí•œì§€ ì„¤ëª…í•´ë³´ì„¸ìš”...",
            key=f"reason_{scenario_id}",
            height=100
        )
        
        # ë‹µë³€ ì œì¶œ ë²„íŠ¼
        if st.button(f"ë‹µë³€ ì œì¶œ", key=f"submit_{scenario_id}"):
            if best_stat != "ì„ íƒí•˜ì„¸ìš”" and reason.strip():
                with st.spinner("ğŸ¤– AIê°€ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    
                    if USE_AI and client:
                        # ì‹¤ì œ OpenAI API í”¼ë“œë°±
                        try:
                            scenario_context = {
                                1: "ì œê¸°ì°¨ê¸° íšŸìˆ˜ ë°ì´í„°: [4, 5, 6, 6, 6, 7, 7, 23]. ì—¬ê¸°ì„œ 23ì€ ê·¹ë‹¨ê°’ì…ë‹ˆë‹¤.",
                                2: "ì‹ ë°œ íŒë§¤ ì‚¬ì´ì¦ˆ ë°ì´í„°: [250, 250, 250, 260, 260, 270, 280]. 250ì´ ê°€ì¥ ë§ì´ íŒ”ë ¸ìŠµë‹ˆë‹¤."
                            }
                            
                            prompt = f"""
ë‹¹ì‹ ì€ ì¤‘í•™êµ í†µê³„ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ ëŒ€í‘¯ê°’ ë¬¸ì œì— ëŒ€í•´ ë‹µë³€í–ˆìŠµë‹ˆë‹¤.

ìƒí™©: {scenario_context[scenario_id]}
í•™ìƒì´ ì„ íƒí•œ ëŒ€í‘¯ê°’: {best_stat}
í•™ìƒì˜ ì´ìœ : {reason}

í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³  í”¼ë“œë°±í•´ì£¼ì„¸ìš”:
1. ì„ íƒí•œ ëŒ€í‘¯ê°’ì´ ì ì ˆí•œì§€ íŒë‹¨
2. ì´ìœ ê°€ íƒ€ë‹¹í•œì§€ ë¶„ì„  
3. ê°„ë‹¨í•˜ê³  ì¹œê·¼í•œ í”¼ë“œë°± ì œê³µ (2-3ë¬¸ì¥)
4. ì¹­ì°¬ ë˜ëŠ” ê°œì„ ì  ì œì‹œ

ì‘ë‹µì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”:
- "âœ… í›Œë¥­í•©ë‹ˆë‹¤!" (ì •ë‹µì¸ ê²½ìš°)
- "ğŸ’­ ì¢‹ì€ ì‹œë„ì…ë‹ˆë‹¤!" (ë¶€ë¶„ì •ë‹µì¸ ê²½ìš°)  
- "ğŸ¤” ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!" (ì˜¤ë‹µì¸ ê²½ìš°)
"""

                            response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[{"role": "user", "content": prompt}],
                                max_tokens=200,
                                temperature=0.7
                            )
                            
                            ai_feedback = response.choices[0].message.content
                            
                            # í”¼ë“œë°± í‘œì‹œ
                            if "âœ… í›Œë¥­í•©ë‹ˆë‹¤!" in ai_feedback:
                                st.markdown(f"""
                                <div class="feedback-positive">
                                    {ai_feedback}
                                </div>
                                """, unsafe_allow_html=True)
                            elif "ğŸ’­ ì¢‹ì€ ì‹œë„ì…ë‹ˆë‹¤!" in ai_feedback:
                                st.markdown(f"""
                                <div class="feedback-negative">
                                    {ai_feedback}
                                </div>
                                """, unsafe_allow_html=True)
                            else:
                                st.markdown(f"""
                                <div class="feedback-negative">
                                    {ai_feedback}
                                </div>
                                """, unsafe_allow_html=True)
                                
                        except Exception as e:
                            st.error(f"AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            USE_AI = False  # ì˜¤ë¥˜ ì‹œ ë°±ì—… ëª¨ë“œë¡œ ì „í™˜
                    
                    if not USE_AI:
                        # ë°±ì—… í”¼ë“œë°± (ê¸°ì¡´ ë¡œì§)
                        time.sleep(1)  # ë¡œë”© ì‹œë®¬ë ˆì´ì…˜
                        correct_answers = {
                            1: {"stats": ["ì¤‘ì•™ê°’", "ìµœë¹ˆê°’"], "keywords": ["ê·¹ë‹¨ê°’", "ì´ìƒì¹˜", "ì™œê³¡", "ì˜í–¥", "ê·¹ë‹¨"]},
                            2: {"stats": ["ìµœë¹ˆê°’"], "keywords": ["ë§ì´ íŒ”ë¦°", "ë¹ˆë„", "ìì£¼", "í”í•œ"]}
                        }
                        
                        correct = correct_answers[scenario_id]
                        is_correct_stat = best_stat in correct["stats"]
                        has_key_reason = any(keyword in reason.lower() for keyword in correct["keywords"])
                        
                        if is_correct_stat and has_key_reason:
                            st.markdown("""
                            <div class="feedback-positive">
                                âœ… <strong>í›Œë¥­í•©ë‹ˆë‹¤!</strong><br>
                                ìƒí™©ì— ê°€ì¥ ì ì ˆí•œ ëŒ€í‘¯ê°’ì„ ì„ íƒí•˜ê³  íƒ€ë‹¹í•œ ì´ìœ ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
                            </div>
                            """, unsafe_allow_html=True)
                        elif is_correct_stat:
                            st.markdown("""
                            <div class="feedback-negative">
                                ğŸ’­ <strong>ëŒ€í‘¯ê°’ ì„ íƒì€ ë§ì§€ë§Œ</strong><br>
                                ì´ìœ ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”. ìë£Œì˜ íŠ¹ì„±ì„ ê³ ë ¤í•´ë³´ì„¸ìš”!
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown("""
                            <div class="feedback-negative">
                                ğŸ¤” <strong>ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!</strong><br>
                                ìë£Œì˜ ë¶„í¬ì™€ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ëŒ€í‘¯ê°’ì„ ì„ íƒí•´ë³´ì„¸ìš”.
                            </div>
                            """, unsafe_allow_html=True)
                
                st.session_state.answers_submitted[scenario_id] = True
            else:
                st.error("âŒ ëŒ€í‘¯ê°’ê³¼ ì´ìœ ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# êµ¬ë¶„ì„ 
st.markdown("---")

# AI ê°€ì´ë“œ ì„¹ì…˜
st.header("âœ… ì–´ë–¤ ëŒ€í‘¯ê°’ì„ ì“°ë©´ ì¢‹ì„ê¹Œ?")

# ê° ëŒ€í‘¯ê°’ë³„ ì˜ˆì‹œ ì…ë ¥ ì„¹ì…˜
stat_types = {
    'mean': {'name': 'í‰ê· ', 'emoji': 'ğŸ“', 'color': '#667eea'},
    'median': {'name': 'ì¤‘ì•™ê°’', 'emoji': 'ğŸ“', 'color': '#38b2ac'},
    'mode': {'name': 'ìµœë¹ˆê°’', 'emoji': 'ğŸ¯', 'color': '#f6ad55'}
}

for stat_key, stat_info in stat_types.items():
    st.markdown(f"""
    <div class="ai-section">
        <h3>{stat_info['emoji']} {stat_info['name']}ì€ ì–´ë–¤ ìƒí™©ì—ì„œ ì“°ë©´ ì¢‹ì„ê¹Œ?</h3>
    </div>
    """, unsafe_allow_html=True)
    
    col_left, col_right = st.columns([2, 1])
    
    with col_left:
        example_text = st.text_area(
            f"{stat_info['name']}ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  ìƒê°í•˜ëŠ” êµ¬ì²´ì ì¸ ìƒí™©ì´ë‚˜ ì˜ˆì‹œë¥¼ ì ì–´ë³´ì„¸ìš”:",
            placeholder=f"ì˜ˆ: {stat_info['name']}ì„ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ ìƒí™©ì„ ì„¤ëª…í•´ë³´ì„¸ìš”...",
            key=f"{stat_key}_example",
            height=120
        )
    
    with col_right:
        if st.button(f"ğŸ¤– AIê°€ í™•ì¸í•´ë³´ê¸°", key=f"check_{stat_key}"):
            if example_text.strip():
                with st.spinner("ğŸ¤– AIê°€ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    
                    if USE_AI and client:
                        # ì‹¤ì œ OpenAI API ë¶„ì„
                        try:
                            stat_names = {'mean': 'í‰ê· ', 'median': 'ì¤‘ì•™ê°’', 'mode': 'ìµœë¹ˆê°’'}
                            stat_name = stat_names[stat_key]
                            
                            prompt = f"""
ë‹¹ì‹ ì€ ì¤‘í•™êµ í†µê³„ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ {stat_name}ì„ ì‚¬ìš©í•˜ëŠ” ìƒí™© ì˜ˆì‹œë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.

í•™ìƒì˜ ì˜ˆì‹œ: {example_text}

ì´ ì˜ˆì‹œê°€ {stat_name}ì„ ì‚¬ìš©í•˜ê¸°ì— ì ì ˆí•œ ìƒí™©ì¸ì§€ í‰ê°€í•´ì£¼ì„¸ìš”:

{stat_name}ì´ ì ì ˆí•œ ê²½ìš°:
- í‰ê· : ìë£Œê°€ ê³ ë¥´ê²Œ ë¶„í¬, ê·¹ë‹¨ê°’ ì—†ìŒ, ì „ì²´ì  ìˆ˜ì¤€ íŒŒì•…
- ì¤‘ì•™ê°’: ê·¹ë‹¨ê°’ ì¡´ì¬, ì¹˜ìš°ì¹œ ë¶„í¬, ì¤‘ê°„ê°’ì´ ì¤‘ìš”  
- ìµœë¹ˆê°’: ë¹ˆë„ê°€ ì¤‘ìš”, ê°€ì¥ í”í•œ ê°’, ë²”ì£¼í˜• ìë£Œ

ì‘ë‹µì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”:
- "âœ… í›Œë¥­í•©ë‹ˆë‹¤!" (ì ì ˆí•œ ê²½ìš°)
- "ğŸ‘ ì¢‹ìŠµë‹ˆë‹¤!" (ë¶€ë¶„ì ì ˆí•œ ê²½ìš°)
- "ğŸ’¡ ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!" (ë¶€ì ì ˆí•œ ê²½ìš°)

ê·¸ ë‹¤ìŒ 1-2ë¬¸ì¥ìœ¼ë¡œ ì¹œê·¼í•˜ê²Œ í”¼ë“œë°±í•´ì£¼ì„¸ìš”.
"""

                            response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[{"role": "user", "content": prompt}],
                                max_tokens=150,
                                temperature=0.7
                            )
                            
                            ai_response = response.choices[0].message.content
                            
                            # í”¼ë“œë°± í‘œì‹œ
                            if "âœ… í›Œë¥­í•©ë‹ˆë‹¤!" in ai_response:
                                st.success(ai_response)
                            elif "ğŸ‘ ì¢‹ìŠµë‹ˆë‹¤!" in ai_response:
                                st.info(ai_response)
                            else:
                                st.warning(ai_response)
                                
                        except Exception as e:
                            st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            USE_AI = False  # ì˜¤ë¥˜ ì‹œ ë°±ì—… ëª¨ë“œë¡œ ì „í™˜
                    
                    if not USE_AI:
                        # ë°±ì—… ë¶„ì„ (ê¸°ì¡´ ë¡œì§)
                        time.sleep(1)  # ë¡œë”© ì‹œë®¬ë ˆì´ì…˜
                        analysis_rules = {
                            'mean': {
                                'good_keywords': ['ê³ ë¥´ê²Œ', 'ê· ë“±', 'ì¼ì •', 'ë¹„ìŠ·', 'í‰ê· ì ', 'ê³ ë£¨', 'ë¶„í¬'],
                                'bad_keywords': ['ê·¹ë‹¨', 'ì´ìƒì¹˜', 'íŠ€ëŠ”', 'ì¹˜ìš°ì³', 'ë¹ˆë„']
                            },
                            'median': {
                                'good_keywords': ['ê·¹ë‹¨', 'ì´ìƒì¹˜', 'íŠ€ëŠ”', 'ì¹˜ìš°ì³', 'ì™œê³¡', 'í•œìª½ìœ¼ë¡œ'],
                                'bad_keywords': ['ê³ ë¥´ê²Œ', 'ê· ë“±', 'í‰ê· ì ', 'ë¹ˆë„']
                            },
                            'mode': {
                                'good_keywords': ['ë§ì´', 'ìì£¼', 'í”í•œ', 'ì¸ê¸°', 'ë¹ˆë„', 'íŒë§¤ëŸ‰', 'ìµœë‹¤'],
                                'bad_keywords': ['í‰ê· ', 'ì¤‘ê°„', 'ê· ë“±', 'ê³ ë¥´ê²Œ']
                            }
                        }
                        
                        rule = analysis_rules[stat_key]
                        lower_text = example_text.lower()
                        
                        has_good = any(keyword in lower_text for keyword in rule['good_keywords'])
                        has_bad = any(keyword in lower_text for keyword in rule['bad_keywords'])
                        
                        if has_good and not has_bad:
                            st.success(f"âœ… í›Œë¥­í•©ë‹ˆë‹¤! {stat_info['name']}ì´ ì ì ˆí•œ ìƒí™©ì„ ì˜ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.")
                        elif has_good:
                            st.info(f"ğŸ‘ ì¢‹ìŠµë‹ˆë‹¤! {stat_info['name']}ì˜ íŠ¹ì„±ì„ ì˜ ì´í•´í•˜ê³  ìˆì–´ìš”.")
                        else:
                            st.warning(f"ğŸ’¡ {stat_info['name']}ì´ ì™œ ì ì ˆí•œì§€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”!")
                
                st.session_state.ai_examples_checked[stat_key] = True
            else:
                st.error("âŒ ì˜ˆì‹œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ê²°ë¡  ì„¹ì…˜
st.markdown("---")
st.markdown("""
<div class="main-header">
    <h2>ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸!</h2>
    <p>ğŸ’¡ <strong>ì™„ë²½í•œ ëŒ€í‘¯ê°’ì€ ì—†ì–´ìš”!</strong><br>
    ìƒí™©ê³¼ ëª©ì ì— ë§ëŠ” <strong>ê°€ì¥ ì ì ˆí•œ ëŒ€í‘¯ê°’</strong>ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤! âœ¨</p>
</div>
""", unsafe_allow_html=True)

# ì§„ë„ ì²´í¬
completed_activities = 0
total_activities = 5  # 2ê°œ ì‹œë‚˜ë¦¬ì˜¤ + 3ê°œ AI ì˜ˆì‹œ

completed_activities += len(st.session_state.answers_submitted)
completed_activities += len(st.session_state.ai_examples_checked)

progress_bar = st.progress(completed_activities / total_activities)
st.write(f"ì§„ë„ìœ¨: {completed_activities}/{total_activities} ì™„ë£Œ ({int(completed_activities/total_activities*100)}%)")

if completed_activities == total_activities:
    st.balloons()
    st.success("ğŸ‰ ëª¨ë“  í™œë™ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì„¸ìš”!")